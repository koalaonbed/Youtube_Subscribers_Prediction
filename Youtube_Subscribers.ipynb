{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36224846",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "490bb6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Loading Data ********\n",
      "No. of rows: 1095242\n",
      "No. of columns: 16\n"
     ]
    }
   ],
   "source": [
    "filepath=\"youtube_channels_1M_clean.csv\"\n",
    "model = 'Gradient Boosting'\n",
    "subscribers = 1  #  1: Predict subscrbers  ;  0: Predict total views\n",
    "\n",
    "#df = pd.read_csv(filepath, sep=\"\\t\", encoding='utf-8')\n",
    "df = pd.read_csv(filepath)\n",
    "print(\"******* Loading Data ********\")\n",
    "print(\"No. of rows: {}\".format(df.shape[0]))\n",
    "print(\"No. of columns: {}\".format(df.shape[1]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f63ea87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selecting columns needed for processing: channel_id, channel_name, subscriber_count, description, keywords, total_views\n",
      "No. of rows (After dropping null): 546994\n",
      "No. of columns: 6\n",
      "No of rows (After removing duplicates): 546994\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_id</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>subscriber_count</th>\n",
       "      <th>description</th>\n",
       "      <th>keywords</th>\n",
       "      <th>total_views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UC28mqg7IlYWEhrZwHb72IQA</td>\n",
       "      <td>Food 'n' Happiness</td>\n",
       "      <td>0</td>\n",
       "      <td>Hello viewers.\\n I am Veena from Mangalore, Ka...</td>\n",
       "      <td>food n happiness, food and happiness, food, Fo...</td>\n",
       "      <td>592961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UCoLwWY9zQ7Jp8aDtYUszmYg</td>\n",
       "      <td>Tim Shieff</td>\n",
       "      <td>166000</td>\n",
       "      <td>The journey of rediscovery.\\n\\nhttps://rdscvr.com</td>\n",
       "      <td>Tim, shieff, timothy, health, human, spiritual...</td>\n",
       "      <td>27250763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UCAQOeJwsgBMC74-OjjcQcJA</td>\n",
       "      <td>Jerry &amp; Julie Music</td>\n",
       "      <td>1090</td>\n",
       "      <td>Welcome to Jerry &amp; Julie Music.  We hope you w...</td>\n",
       "      <td>jerryandjuliemusic, jerryspianobar, juliesguit...</td>\n",
       "      <td>339906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UCkcc9W34khoJeQA6Eypp0JA</td>\n",
       "      <td>Burhan &amp; Zohan</td>\n",
       "      <td>617</td>\n",
       "      <td>Welcome To My Channel ..!!♥️ Hi I Am Mommy Of ...</td>\n",
       "      <td>Burhan &amp; Zohan, cooking and vlogging, lifestyl...</td>\n",
       "      <td>36995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UCmDLg3tp5998ODVPHv51aPg</td>\n",
       "      <td>Jenny taylor</td>\n",
       "      <td>278</td>\n",
       "      <td>Let's get healthy!\\n\\nWelcome to my channel! \\...</td>\n",
       "      <td>Disease proof, health</td>\n",
       "      <td>54293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 channel_id         channel_name  subscriber_count  \\\n",
       "1  UC28mqg7IlYWEhrZwHb72IQA   Food 'n' Happiness                 0   \n",
       "2  UCoLwWY9zQ7Jp8aDtYUszmYg           Tim Shieff            166000   \n",
       "3  UCAQOeJwsgBMC74-OjjcQcJA  Jerry & Julie Music              1090   \n",
       "5  UCkcc9W34khoJeQA6Eypp0JA       Burhan & Zohan               617   \n",
       "6  UCmDLg3tp5998ODVPHv51aPg         Jenny taylor               278   \n",
       "\n",
       "                                         description  \\\n",
       "1  Hello viewers.\\n I am Veena from Mangalore, Ka...   \n",
       "2  The journey of rediscovery.\\n\\nhttps://rdscvr.com   \n",
       "3  Welcome to Jerry & Julie Music.  We hope you w...   \n",
       "5  Welcome To My Channel ..!!♥️ Hi I Am Mommy Of ...   \n",
       "6  Let's get healthy!\\n\\nWelcome to my channel! \\...   \n",
       "\n",
       "                                            keywords  total_views  \n",
       "1  food n happiness, food and happiness, food, Fo...       592961  \n",
       "2  Tim, shieff, timothy, health, human, spiritual...     27250763  \n",
       "3  jerryandjuliemusic, jerryspianobar, juliesguit...       339906  \n",
       "5  Burhan & Zohan, cooking and vlogging, lifestyl...        36995  \n",
       "6                              Disease proof, health        54293  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nSelecting columns needed for processing: channel_id, channel_name, subscriber_count, description, keywords, total_views\")\n",
    "\n",
    "df = df[['channel_id', 'channel_name', 'subscriber_count', 'description', 'keywords', 'total_views']]\n",
    "df['description'] = df['description'].astype(str)\n",
    "\n",
    "df[\"description\"] = df[\"description\"].apply(lambda x: x.strip())\n",
    "\n",
    "\n",
    "df=df.dropna()\n",
    "df['total_views'] = df['total_views'].astype(int)\n",
    "print(\"No. of rows (After dropping null): {}\".format(df.shape[0]))\n",
    "print(\"No. of columns: {}\".format(df.shape[1]))\n",
    "\n",
    "\n",
    "df.drop_duplicates(subset=['channel_id'], keep='first', inplace=True)\n",
    "print(\"No of rows (After removing duplicates): {}\".format(df.shape[0]))\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcb01d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_views'].median()\n",
    "df['subscriber_count'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61d5283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"total_views\"] = df[\"total_views\"].apply(lambda x: 1 if x >232200.5 else 0)\n",
    "df[\"subscriber_count\"] = df[\"subscriber_count\"].apply(lambda x: 1 if x >1190 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13917d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(X, y, model):\n",
    "    \n",
    "    \"\"\"\n",
    "      Seceral fitting models to choose from:\n",
    "      Decision Tree, SVM, Logistic Regression, Random Forest, Gradient Boosting\n",
    "    \"\"\"\n",
    "    \n",
    "    if model=='Decision Tree':\n",
    "        model = DecisionTreeClassifier(max_depth=2).fit(X, y)\n",
    "    elif model=='SVM':\n",
    "        model = SVC(kernel='linear', probability=True).fit(X, y)\n",
    "    elif model=='Logistic Regression':\n",
    "        model = LogisticRegression().fit(X, y)   \n",
    "    elif model=='Random Forest':\n",
    "        model = RandomForestClassifier(max_depth=3).fit(X, y)\n",
    "    elif model=='Gradient Boosting':\n",
    "        model = GradientBoostingClassifier().fit(X, y)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bb30aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y, y_pred):\n",
    "    #evaluate model performance\n",
    "\n",
    "    \n",
    "    \n",
    "    print('\\n************* Model Evaluation *************\\n')\n",
    "    \n",
    "    print('Confusion Matrix:\\n')\n",
    "    print(confusion_matrix(y, y_pred))\n",
    "    print('\\nClassification Report:\\n')\n",
    "    print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d557021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X_data__raw):\n",
    "    # Preprocess data\n",
    "\n",
    "    X_data=X_data__raw.iloc[:, 3].astype(str)\n",
    "\n",
    "    # Convert characters to lowercase\n",
    "    X_data = X_data.map(lambda x: x.lower())\n",
    "    X_data = X_data.str.replace('[^\\w\\s]', '')\n",
    "\n",
    "    # Tokenize sentence\n",
    "    X_data = X_data.apply(nltk.word_tokenize)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stopword_list = stopwords.words(\"english\")\n",
    "    X_data = X_data.apply(lambda x: [word for word in x if word not in stopword_list])\n",
    "\n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    X_data = X_data.apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "    X_data = X_data.apply(lambda x: \" \".join(x))\n",
    "\n",
    "    return X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67251254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: (437595, 5)\n",
      "Validation Data: (54699, 5)\n",
      "Test Data: (54700, 5)\n",
      "\n",
      "Class Counts(label, row): Train\n",
      "0    219355\n",
      "1    218240\n",
      "Name: subscriber_count, dtype: int64\n",
      "\n",
      "Class Counts(label, row): Val\n",
      "0    27419\n",
      "1    27280\n",
      "Name: subscriber_count, dtype: int64\n",
      "\n",
      "Class Counts(label, row): Test\n",
      "0    27420\n",
      "1    27280\n",
      "Name: subscriber_count, dtype: int64\n",
      "\n",
      "Data View: X Train\n",
      "                      channel_id              channel_name  subscriber_count  \\\n",
      "92632   UC8wXC0ZCfGt3HaVLy_fdTQw            Digital Trends                 1   \n",
      "772390  UCVEpo47Y0mIeOm0kJOgqrCg  Connecticut State Police                 1   \n",
      "779043  UCV7W0JDXFLeaVU9ER-S4w6g         Internet e Coisas                 1   \n",
      "\n",
      "                                              description  \\\n",
      "92632   Digital Trends was founded in 2006 with a simp...   \n",
      "772390  This is the official YouTube Channel of the Co...   \n",
      "779043  Você é Maker de Internet das Coisas? Então ess...   \n",
      "\n",
      "                                                 keywords  \n",
      "92632   tech, review, home theater, smartphone, smart ...  \n",
      "772390                                   Law, enforcement  \n",
      "779043  Acessórios, Aprendizado, Arduino, Automação, C...  \n",
      "\n",
      "Data View: X Val\n",
      "                      channel_id            channel_name  subscriber_count  \\\n",
      "924156  UCET9Q_yCgo2fBneuD7Lvuww                  Launch                 0   \n",
      "270293  UCapkfYy5RfWWZ5Tbo6w954g  Sfiso Goodman Mahlangu                 0   \n",
      "765555  UCM3fJ2fDoPfEvhQiygz61Jg   Cha Gudi Ng Singapore                 1   \n",
      "\n",
      "                                              description  \\\n",
      "924156  See more of our work at http://www.launchadver...   \n",
      "270293                                                nan   \n",
      "765555  #ChaGudiNgSingapore\\n#Lifestyle\\n#Cooking\\n#tu...   \n",
      "\n",
      "                                                 keywords  \n",
      "924156  advertising, marketing, communications, denver...  \n",
      "270293  DJ Fistos, South African House Mix, Black Coff...  \n",
      "765555  Cha Gudi Ng Singapore, Cha Gudi, Singapore, Co...  \n",
      "\n",
      "Data View: X Test\n",
      "                       channel_id    channel_name  subscriber_count  \\\n",
      "950910   UCL0pcAGV4g67jCxGIPWv9iQ     Oak Studios                 1   \n",
      "1042205  UCN3boqyMVVraUgE4jjfkvXQ          Stevie                 0   \n",
      "68846    UC9bBNVnPE4jy8ZtXRzQz81g  Tali's Kitchen                 1   \n",
      "\n",
      "                                               description  \\\n",
      "950910   Hi there! We make music for content creators a...   \n",
      "1042205  Join my channel to discover new products relat...   \n",
      "68846    Tali's Kitchen is a channel for everyone!  Tal...   \n",
      "\n",
      "                                                  keywords  \n",
      "950910   oak studios, no copyright music, background mu...  \n",
      "1042205  makeup, skincare, hair care, clean with me, bu...  \n",
      "68846    talis kitchen, talis, talis, talis kitchen, ta...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7312/2644908348.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  X_data = X_data.str.replace('[^\\w\\s]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************* Pre-processed Data ***************\n",
      "\n",
      "Train Data:  (437595,)\n",
      "\n",
      "Data View: X Train\n",
      "0    digit trend found 2006 simpl mission give read...\n",
      "1    offici youtub channel connecticut state polic ...\n",
      "2    você é maker de internet da coisa então ess é ...\n",
      "Name: description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "if subscribers:\n",
    "    X, y = df.iloc[:, :-1], df.iloc[:, 2]\n",
    "else:\n",
    "    X, y = df.iloc[:, :-1], df.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=69, stratify=y_test)\n",
    "\n",
    "print(\"Train Data: {}\".format(X_train.shape))\n",
    "print(\"Validation Data: {}\".format(X_val.shape))\n",
    "print(\"Test Data: {}\".format(X_test.shape))\n",
    "\n",
    "print('\\nClass Counts(label, row): Train')\n",
    "print(y_train.value_counts())\n",
    "print('\\nClass Counts(label, row): Val')\n",
    "print(y_val.value_counts())\n",
    "print('\\nClass Counts(label, row): Test')\n",
    "print(y_test.value_counts())\n",
    "\n",
    "print(\"\\nData View: X Train\")\n",
    "print(X_train.head(3))\n",
    "print(\"\\nData View: X Val\")\n",
    "print(X_val.head(3))\n",
    "print(\"\\nData View: X Test\")\n",
    "print(X_test.head(3))\n",
    "\n",
    "# Reset index   \n",
    "X_train=X_train.reset_index(drop=True)\n",
    "X_val=X_val.reset_index(drop=True)\n",
    "X_test=X_test.reset_index(drop=True)\n",
    "\n",
    "y_train=y_train.reset_index(drop=True)\n",
    "y_val=y_val.reset_index(drop=True)\n",
    "y_test=y_test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Preprocess data\n",
    "\n",
    "X_train_processed = preprocess(X_train)\n",
    "\n",
    "print(\"\\n************* Pre-processed Data ***************\")\n",
    "print(\"\\nTrain Data: \", X_train_processed.shape)\n",
    "print(\"\\nData View: X Train\")\n",
    "print(X_train_processed.head(3))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0dbc0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# transforming data\n",
    "\n",
    "count_vect = CountVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
    "counts = count_vect.fit_transform(X_train_processed)\n",
    "transformer = TfidfTransformer(smooth_idf=True, use_idf=True).fit(counts)\n",
    "X_train_transformed = transformer.transform(counts)\n",
    "\n",
    "X_train_t = X_train_transformed\n",
    "y_train_t = y_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dae47149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Training Model: Gradient Boosting *************\n",
      "\n",
      "\n",
      "*************** Getting predictions **************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7312/2644908348.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  X_data = X_data.str.replace('[^\\w\\s]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Evaluating performance **************\n",
      "\n",
      "************* Model Evaluation *************\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[15360 12060]\n",
      " [11008 16272]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.56      0.57     27420\n",
      "           1       0.57      0.60      0.59     27280\n",
      "\n",
      "    accuracy                           0.58     54700\n",
      "   macro avg       0.58      0.58      0.58     54700\n",
      "weighted avg       0.58      0.58      0.58     54700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model fitting\n",
    "\n",
    "\n",
    "print(\"\\n************** Training Model: \" + model + \" *************\")\n",
    "y_train_t = y_train_t.astype(int)\n",
    "model = fit_model(X_train_t, y_train_t, model=model)\n",
    "\n",
    "## prediction\n",
    "\n",
    "print(\"\\n\\n*************** Getting predictions **************\")\n",
    "\n",
    "X_test_processed = preprocess(X_test)\n",
    "counts_test = count_vect.transform(X_test_processed)\n",
    "X_test_t = transformer.transform(counts_test)\n",
    "y_pred = model.predict(X_test_t)\n",
    "\n",
    "## 7. Evaluating model performance\n",
    "\n",
    "print(\"\\n************** Evaluating performance **************\")\n",
    "\n",
    "evaluate_model(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c042cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f0ff83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
